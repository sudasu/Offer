# [特征工程](https://www.biaodianfu.com/categorical-feature.html)

categorical feature特征一般是指职业，血型等有限类别内取值的字符串形式特征。

## Label encoding

Label Encoding使用字典的方式将每个类别标签和不断增加的整数相关联，既生成一个实例数组。

```python

# fit(y): fit是一个空字典，y为字典中的词，自然key就是之前所描述的数字
# transform(y) : 根据y获取索引值
# inverse_transform(y) : 根据索引值获取原始数据
# fit_transform(y) : 相当于先fit再transform，即先填充字典后再得到所有的索引值
# 注意 : y都得是数组类型

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
city_list = ["paris", "paris", "tokyo", "amsterdam"]
le.fit(city_list)

# pandas的factorize()函数也具有类似的功能，返回一个元组

import pandas as pd
df = pd.DataFrame(['green','bule','red','bule','green'],columns=['color'])
pd.factorize(df['color'])  
#(array([0, 1, 2, 1, 0], dtype=int64),Index(['green', 'bule', 'red'], dtype='object'))

```

## 序列编码(Ordinal Encoding)

即最简单的将m个category的Feature映射至[0,m-1]的整数，但无法反应出分类之间的关系。

## 独热编码(One-Hot Encoding)

优点：独热编码解决了分类器不好处理属性数据的问题，在一定程度上也起到了扩充特征的作用。它的值只有0和1，不同的类型存储在垂直的空间。
缺点：当类别的数量很多时，特征空间会变得非常大。在这种情况下，一般可以用PCA（主成分分析）来减少维度。而且One-Hot Encoding+PCA这种组合在实际中也非常有用。

```python
from sklearn.preprocessing import LabelBinarizer
 
lb = LabelBinarizer()
 
city_list = ["paris", "paris", "tokyo", "amsterdam"]
 0
print(lb.classes_)  # 输出为：['amsterdam' 'paris' 'tokyo']
 
city_list_le = lb.transform(city_list)  # 进行Encode
print(city_list_le)  # 输出为：
# [[0 1 0]
#  [0 1 0]
#  [0 0 1]
#  [1 0 0]]
 
city_list_new = lb.inverse_transform(city_list_le)  # 进行decode
print(city_list_new)  # 输出为：['paris' 'paris' 'tokyo' 'amsterdam']
```
