# 基础

## 常见问题

### 新建的Consumer从哪儿开始消费消息？

1. 如果topic在3天内发送过消息，consumer将会从保存在server里的最新消息。
2. 如果topic没有在3天内发送消息，consumer将会从server的尾端开始消费消息。
3. 如果消费者是重启的状态，则会从上次消费的位置开始消费消息。
4. 可以自定义消费的模式，如CONSUMER_FROM_LAST_OFFSET将会从最新的消息开始消费,如果是CONSUME_FROM_FIRST_OFFSET则会消费存在在BROKER中的所有消息，也可以定义CONSUMMER_FROM_TIMESTAMP按自定义时间开始消费。

### 当消费失败时，是如何重新消费消息的？

1. 如果是在集群模式，消费者的业务逻辑代码将会返回NULL,Action,ReconsumerLaater或者抛出异常。然后继续重复尝试16次消费动作，如果还未被正确消费该消息将会被抛弃。
2. 如果是广播模式，仍然会保证消息至少会被消费一次，但是 no resend option is provided(不理解啥意思)

### 如何查询被消费失败的消息(用的少所以不理解)

1. 通过时间使用topic查询，将可以查询一段时间内的消息。
2. 使用Topic和消息id精确查询消息
3. 或者使用Topic和message key精确查询某一类拥有相同message key的消息。

### 如何保证消息只被传递一次

RocketMQ只能确保所有消息不止被传递一次，在大多数情况下消息是不会重复的。

### 默认的配置问题

一般消息都只会存3天，其中未使用超过三天的消息将会被删除(这样说使用和未使用有啥区别呢？)。还有就是message Body一般长度就256KB。

### 消息一致性

从消息的传递流程来看，producer->master broker->slave broker->consumer。首先为了保证消息确实传递成功，在不同进程间肯定有相应应答机制保证。对于producer->master和slave->consumer，通过应答保证至少有一次成功。master自身可以通过同步刷盘保证消息正确持久化，也可以通过同步从节点保证可用性，但官网建议使用主从而不是同步刷盘，是因为同步刷盘代价更高(同步双写可以保证完全避免单点故障)？(如果接收到了SEND_OK，则表示接收成功，但如果失败则会按如下逻辑抛出异常。如果在同步刷盘模式下，在5秒内刷盘失败会得到FLUSH\_DISK\_TIMEOUT的异常。同理，在同步主从的模式下，5秒内同步失败，会有FLUSHS\_SLAVE\_TIMEOUT异常。如果主节点配置的是同步主从模式，而没有配置从节点或无从节点可用时，会产生SLAVE\_NOT\_AVAILABLE的异常。)对于broker崩溃的同时，出现timeout(同步的，而不是发送的)异常，可能需要重新发送消息以保证消息确实发送成功，此时需要保证幂等性避免重复消费。

## 消息过滤

rocketmq的过滤通过tag来实现，其中这部分内容由broker承担，主要是为了减少网络传播，但这样会增加broker的负担。

## 回溯消费

rocketmq提供按毫秒级的维度回复。

## 重复消息出现的情况

## 组件架构

* NameServer: NameServer就是个Topic路由注册中心，动态维护Topic和Broker之间的关系包括套接字,messege queue等信息，然后通过心跳检测Broker的存活。其中集群模式是通过点对点实现的，各个server相互独立。
* BrokerServer:Broker主要由5个模块组成：1.Remoting Module,负责处理远端的请求。2.Client Manager,负责管理客户端(p/c)的Topic相关信息。3.Store Service,硬盘存储查询相关功能。4.HA Service，负责主从的数据同步。5.Index Service,负责完成快速的索引检索。Broker支持主从模式，即BrokerName相同但BrokerId不同，其中0表示主，非零表示从，而且只有1才会参与消息的读负载(BrokerId是否允许重复，据此分析从的不同功能。)

## 消息存储架构

* CommitLog: 采用追加写的方式写入多个log文件，单个文件大小默认1G ，文件名长度为20位，左边补零。即，单个文件offset为1G=1073741824，所以第二个文件的文件名为00000000001073741824。(是否会出现跨文件消息的情况，还是说空余？应该是会存在跨文件消息的情况，毕竟只用记录offset即可，不用浪费空间。CommitLog的一个数据单元的组成是咋样的呢，一定是包含topic,queueId,messageBody这样的结构组成的吗？感觉有queue的存在完全可以只存储数据。这可能是由于queue是动态维护的？)
* ConsumeQueue: 基于topic\queue\file存储结构的逻辑队列，存储offset信息主要用来当作索引进行检索，由8字节commitlog offset、4字节消息长度和8字节tag的hashCode(用来筛选tag)三部分内容组成。由于数据单元大小固定，一个文件存储30w个数据单元，大约5.72M大小。(根据下图，似乎commitlog是一个完整的数据文件，mq从逻辑上对msg进行切分，所以横向拓展时每个master的commitlog都是完整的，只有mq才需要分散？)
* IndexFile: 提供可以通过key或时间区间来查询消息的方法,存储名字为index${fileName},其中fileName由创建时的时间戳命名。单个IndexFile的大小约为400M，一个IndexFile可以存2000W索引，底层为文件系统中的HashMap结构。

![s](https://github.com/apache/rocketmq/raw/master/docs/cn/image/rocketmq_design_1.png)
>总结：Broker单个实例所有队列共用一个日志文件(CommitLog)，只要消息被持久化到CommitLog中，Produce发送的消息就不会丢失。RocketMQ的后台线程ReputMessageService会不停的分发请求，异步构建ConsumeQueue和IndexFile数据。

## 负载均衡

* producer基础: producer会随机跟NameServer集群中的一个节点建立长连接，定期获取Topic路由信息，并和提供该Topic服务的master均建立长连接。producer发送消息，首先根据Topic值找到TopicPublishInfo。然后使用selectOneMessageQueue()方法，从Info路由信息中通过选择一个队列发送消息。其中选择策略为，如果没有开启sendLatencyFaultEnable变量，则使用随机递增取模的方式选择队列发送消息，否则会对latency较高的broker采用一定的避让策略，降低broker的压力。
* consumer基础: RocketMQ中,consumer存在两种消费模式push/pull,分别指consumer主动调用方法拉消息和当新的可消费的消息到了后consumer“被动”push接收。但实际consumer的push也是基于pull模式实现的，即当消息拉取到待消费的消息后，立马继续去服务器再拉取消息，如果未拉取到消息则延迟一下又继续拉取，所以这部分内容的负载均衡设计非常重要。(主要包括多个Broker端中的多个queue，如何分配给同一个ConsumerGroup中的多个Consumer。但是有一说一，为什么要这样设计呢，单纯的broker收到新消息直接push不行吗？)其中consumer和producer一样随机与NameServer集群中一个节点建立长连接，并与提供该Topic服务的主从broker建立长连接，并发送心跳(可能会出现多master，queue水平分区的情况，所以所有相关的broker都需要建立长连接。)。consumer的主从读取决策策略与master的判断如读老消息(根据偏移量是否符合范围)会产生的读I/O，服务器是否可用等因素相关。
* consumer的心跳包: consumer在启动后会通过定时任务，不断向RocketMQ集群中的所有(为什么这里是所有？)Broker发送心跳包(包含consumerGroup名称，订阅关系，消息通信模式(集群模式和广播模式)和客户端id(不懂，是指ip地址？)等信息)。Broker端在收到consumer的心跳信息，会将其维护到ConsumerManager的缓存变量consumerTable中，同时将客户端网络通道信息保存到缓存变量channelInfoTable中，为Consumer端的负载均衡提供依据。

### consumer的负载均衡实现

对于consumer端的本地而言，会在实例启动流程中开启RebalanceService相关任务的后台运行(每20s执行一次)。Service通过rebalanceByTopic()方法来完成负载均衡，其中会对消费者的通信类型是广播模式还是集群模式做不同的逻辑处理，此处先介绍更一般的集群模式下的处理:

1. 首先先从本地缓存topicSubscribeInfoTable中获取，该Topic下的messsage queue set(一般情况下此set分散在各个broker)
2. 根据topic和consumerGroup为参数确定消费者id(通过mQClientFactory.findConsumerIdList()方法向broker发起rpc请求获得，其中broker的数据是基于之前维护的consumerTable获取的。这有个疑问，为什么消费者信息需要找broker获取，自己本身不就是消费者吗？可能是增加一次通信，确保broker确实接受到了心跳，而不是宕机了。有没有可能是queue是动态维护的，该topic如果在broker端新增了queue需要让consummer知晓。)
3. 将Topic下的message queues和消费者id进行排序，然后分组分配任务，默认是平均每个consumerId分配到相同的平均queue数。

## 事务消息

如果事务消息的发送者在未commit时崩溃了,broker会寻找该producer group的其他发送者完成commit(这样看来，为了可用性应该需要同producer group集群部署)。
