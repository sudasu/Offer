# 限流

## SLB

SLB(Server Load Banlance)服务通过设置虚拟ip，将同一地域的多台服务器资源虚拟成一个高性能、高可用的应用服务池。再根据应用指定的方式，将来自客户端的网络请求分发到云服务器池中。SLB服务会检查服务器池中服务器的健康状态，自动隔离异常状态的服务器从而解决了单点问题。
[continue...](https://www.cnblogs.com/micro-chen/p/6697889.html)

## BBR算法

### 传统拥塞控制

传统用塞控制算法目标：**公平竞争，充分利用带宽，降低网络延时**  

基于丢包策略的拥塞控制:
![基于丢包策略的拥塞控制](https://s2.51cto.com/oss/202004/10/49db191ad0931857bbf7625515f932b8.jpg-wh_600x-s_2581188743.jpg)

基于延时策略的拥塞控制:
![基于延时策略的拥塞控制](https://s2.51cto.com/oss/202004/10/2e0aa6f0bcc2ce4bfcd8dc6e603df69d.png-wh_600x-s_3393817007.png)

基于丢包策略的拥塞控制发包率高、竞争激烈，但网络状况波动较大呈锯齿状。基于延时策略的算法更为平滑，但当前使用的拥塞控制算法主流还是基于丢包的。

算法原则：**公平性**和**收敛性**

线性增加乘性减少(additive-increase/multiplicative-decrease)算法是一个反馈控制算法，探测性线性增加策略会比指数增加更安全，丢包后的指数减少可以有效缓解拥塞。可这样会对网络通信条件要求较为苛刻，在互联网早期都是通过有线网络进行连接通信的，这时效果是不错的。而时间回到现在，在移动互联网澎湃发展的条件下，外界因素影响丢包的情况越来越多，数据包经过多重路由、交换机、基站等基础通信设备的每个环节都可能会发生异常。这时，基于AIMD的拥塞策略可能会由于丢包的原因而大幅降低网络吞吐量，从而影响带宽的利用率所以我们采用更加激进的控制策略。

延迟时间与对应TCP吞吐量关系:
![latency and throughput](https://s3.51cto.com/oss/202004/10/ae5ac2375cfe80345eddc73615db5a63.jpg)  
分析：对于拥有慢启动阶段的拥塞控制算法，每经过一个RTT周期拥塞窗口cwnd将加倍，但更大的RTT意味着以很低的速率发送数据更多的时间是空闲的，整个吞吐量下降的很明显。(指数增加阶段对RTT非常敏感)

### BBR算法简介

TCP BBR(Bottleneck Bandwidth and Round-trip propagation time)是由Google设计基于模型主动探测，区别于基于丢包作为降低传输速率信号的拥塞算法。  
该算法使用网络<font color="#ff00ff">最近出站数据分组</font>当时的**最大带宽**和**往返时间**来创建网络的显式模型。数据包传输的<u>每个累积或选择性确认</u>(啥意思？)用于生成在数据包传输过程和确认返回期间的时间内所传送数据量的采样率的记录。(<u>不懂</u>)该算法认为随着网络接口控制器(**网卡**)逐渐进入千兆速度时，分组丢失不应该被认为是识别拥塞的主要决定因素。BBR被植入Linux内核4.9版本，并且对QUIC(<b>Quick UDP Internet Connection是谷歌制定的一种基于UDP的低时延的互联网传输层协议</b>)可用。
###基于丢包反馈策略可能存在的问题
**1.丢包即拥塞**

现实中网络环境很复杂会存在错误丢包，很多算法没法区分错误丢包和拥塞丢包，因此如上所说错误丢包过多的情况下会使得某些网络场景不能充分利用带宽。

**缓冲区膨胀问题(BufferBloat)**

网络络连接中路由器、交换机、核心网设备等等为了平滑网络波动而存在缓冲区，这些缓存区就像输液管的膨胀部分让数据更加平稳，但是Loss-Based策略在最初就像网络中发生数据类似于灌水，此时是将Buffer全部算在内的，一旦buffer满了，就可能出现RTT增加丢包等问题，就相当于有的容量本不该算在其中，但是策略是基于包含Buffer进行预测的，特别地在深缓冲区网络就会出现一些问题。(还是看《详解tcp/ip》吧，这块似乎有详细描述，暂时看不懂[...19～23章?](https://www.zhihu.com/question/53283819))

**网络负载高但无丢包事件**

在网络负载很高的情况下，只要没有丢包时间发生算法就不会主动减窗降低发送速率，这样虽然充分利用了网络贷款但表现出了较强的网络带宽侵略性，有比较大的网络负载压力。(经常处于绷紧状态？会造成什么后果呢？设备影响？)

**高负载丢包**

高负载无丢包情况下算法一直加窗，这样可以预测丢包时间可能很快就出现了，一旦丢包出现窗口将呈现乘性减少引起整个网络的瞬时抖动，呈现较大的锯齿状波动。(这里是在说明锯齿状波动不好？不好在哪儿呢，对设备不好，带宽利用率不高？)

**低负载高延时丢包**

在某些弱网环境下RTT会增加甚至出现非拥塞丢包，如上延迟时间与对应TCP吞吐量关系图所示，此时拥塞算法的窗口会比较小对带宽利用率很低，吞吐量下降明显但实际网络负载并不高。
[continue....](https://network.51cto.com/art/202004/614189.htm)