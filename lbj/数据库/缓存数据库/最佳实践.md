# 最佳实践

## 缓存使用策略

### 一般策略

1. redis作为临时缓存，不存入持久型数据库之中。
2. 缓存实时更新，定期存入mysql。
3. mysql实时更新，定期更新redis。
4. 读redis,redis不存在读mysql并存入redis。写mysql,写成功后删除redis，此处需要保证一致性。
5. 直接单维护mysql

### 高并发抢购减一

1. 根据剩余数量的量级不同，进行不同的限流数量。
2. 根据剩余数量的量级不同，使用不同的缓存策略。如数量非常多，可以先使用缓存策略2，然后慢慢根据限流策略提升mysql的写的频率，最后采用策略5。

### 热度排序

1. 由于目前的热度排序对一致性要求没那么大，一般采用策略2，把控好写入频率即可。（关联删除条件注意一下，有可能是mysql的及联删除导致redis没有察觉）
2. 如果需要持久性，可以采用策略3，定期刷redis数据即可。
3. 如果热度排序还对应访问资源，相关的变更一定要实时交互，而不能采用策略3。

### 流量数据缓存报表

1. 查询代价不怎么昂贵，且qps低，所以采用策略5
2. 查询代价非常昂贵，所以应该尽量降低动用mysql的次数，适宜采用策略1和4。
3. 考虑到数据变更导致的查询结果出错的情况，由于很难排查到查询结果与数据变更的影响关系，且数据变更较少。所以不采用策略4，对策略1添加补偿逻辑。补偿逻辑如下：1.重启后删除所有缓存，现方案使用版本号惰性删除。2.缓存持续时间尽量的长，可以与查询时间相关。3.可以增加后台维护接口，更新缓存数据。

## [批量模糊删除](https://www.yisu.com/zixun/144062.html)

或许不支持直接通过redis指令删除，需要使用程序逻辑辅助进行批量删除工作，或是脚本或是代码。

## 禁止大key

大key的产生一般来自于Set,Zset,List,Hash等集合操作，一般集合类数据尽量不要超过10k。如确有如此大的数据量，最好对该key进行拆分。

缺点：

1. 大key数据在一次性写入redis时，很容易将网卡流量占满，导致整个服务器的服务不可用。如1mb的string大key，1秒写入10次就会导致网络I/O达到10MB
2. 在一次性读取大key的值时，也会超时严重，网卡流量占满
3. 一次性删除大key，会长时间阻塞redis进程，对redis集群的可用性造成严重影响。

建议：1.减少大key的使用，分批操作大key里面的数据。2.对大key进行分区拆分

## 应对热点key

热点key的解决方案一般分为两步：
监控发现hot key:1.业务经验判断，如做秒杀、促销之类活动时可以提前预估。2.proxy层收集数据上报
通知系统解决:1.在代码中使用本地缓存，如使用map避免去访问redis。2.将热点key进行拆分，如随机集群id+热点key的组合，分散到多个redis集群。

## lua脚本和伪事务的使用

### 批量给key赋值并设置ttl

像hash类型是不能直接设置ttl的，需要分成两步执行赋值和设置ttl。如果直接拆开成两步来做，由于网络故障，服务崩溃等因素一致性风险较高。而使用redis伪事务，保证一致性风险仅出现在redis侧崩溃，重启。

### watch观测乐观锁

如想要缓存的商品库存不能为负数，先watch shop:num，如果大于1。则执行事务减1，如果watch到shop:num被其他任务改掉了，则返回失败，继续loop重试。

### 如何对hash类型同时使用nx和ex